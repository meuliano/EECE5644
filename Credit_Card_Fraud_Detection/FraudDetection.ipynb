{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('C:\\Users\\meuli\\Desktop\\ML\\EECE5644\\FinalProject'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Imbalance')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "plt.hist(data['Class'], color='red')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Transaction')\n",
    "plt.title('Class Imbalance', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17304750013189596\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "pc_fraud = len(data.loc[data['Class'] == 1].values)/len(data.loc[data['Class'] == 0].values)\n",
    "print(pc_fraud*100)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled train dataset shape Counter({0: 227454, 1: 391})\n",
      "Sampled validation dataset shape Counter({0: 56861, 1: 101})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Original dataset\n",
    "x = data.drop('Class', axis=1).values\n",
    "y = data['Class'].values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Sampled train dataset shape %s' % Counter(ytrain))\n",
    "print('Sampled validation dataset shape %s' % Counter(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bs =100\n",
    "\n",
    "#creating torch dataset and loader using original dataset. \n",
    "#to use resampled dataset, replace ex. xtrain with xtrain_over etc.\n",
    "train_ds = torch.utils.data.TensorDataset(torch.tensor(xtrain).float(), torch.tensor(ytrain).float())\n",
    "valid_ds = torch.utils.data.TensorDataset(torch.tensor(xtest).float(), torch.tensor(ytest).float())\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network class 2-hidden layer model\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, n_input=10, n_hidden = 20, n_output = 1,drop_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.extractor1 = torch.nn.Linear(n_input, n_hidden)\n",
    "        self.extractor2 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.drop_out = torch.nn.Dropout(drop_prob)\n",
    "        self.classifier = torch.nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        x = self.relu(self.extractor1(xb))\n",
    "        x = self.relu(self.extractor2(x))\n",
    "        x = self.drop_out(x)\n",
    "        return self.classifier(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the network\n",
    "def train(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network setting\n",
    "n_input = xtrain.shape[1]\n",
    "n_output = 1\n",
    "n_hidden = 15\n",
    "\n",
    "model = Classifier(n_input=n_input,n_hidden=n_hidden,n_output=n_output,drop_prob=0.2)\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "#for orignal dataset, I use pos_weight.\n",
    "pos_weight = torch.tensor([5])\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "n_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04896211961581128\n",
      "1 0.04806335966745101\n",
      "2 0.047329842957430375\n",
      "3 0.04660354073225679\n",
      "4 0.04564841210638805\n",
      "5 0.04462816001065404\n",
      "6 0.043337437418335886\n",
      "7 0.04160038221370192\n",
      "8 0.03946779663949375\n",
      "9 0.03669009401639322\n",
      "10 0.03389384188184374\n",
      "11 0.031063886416084468\n",
      "12 0.028466187282816757\n",
      "13 0.025887499222991217\n",
      "14 0.02372430297226121\n",
      "15 0.021559454385702757\n",
      "16 0.01969615969089509\n",
      "17 0.018190110755482256\n",
      "18 0.0167992748046242\n",
      "19 0.015705560342496056\n",
      "20 0.01503860175501009\n",
      "21 0.014134874126183552\n",
      "22 0.013548916961149286\n",
      "23 0.013066655243010046\n",
      "24 0.012687963161248076\n",
      "25 0.012461640384000612\n",
      "26 0.01231706821192549\n",
      "27 0.011986736058316903\n",
      "28 0.011757101806128269\n",
      "29 0.011897928800700966\n",
      "30 0.011627498839256638\n",
      "31 0.011483435921831495\n",
      "32 0.011448667220721232\n",
      "33 0.011336398445839821\n",
      "34 0.011283340531473831\n",
      "35 0.011187666358337777\n",
      "36 0.011143308848668829\n",
      "37 0.011040191258071031\n",
      "38 0.011048835583192813\n",
      "39 0.011022652279821153\n",
      "40 0.011026709553654038\n",
      "41 0.010904539788874257\n",
      "42 0.010920759771574839\n",
      "43 0.010909194483416495\n",
      "44 0.010926326941377677\n",
      "45 0.010850469247063732\n",
      "46 0.01081475575934664\n",
      "47 0.010788409966515169\n",
      "48 0.010760956419558461\n",
      "49 0.01075812201112974\n",
      "50 0.01066975110287331\n",
      "51 0.010723069567525383\n",
      "52 0.010715783478373335\n",
      "53 0.01071447022581778\n",
      "54 0.01070005689948825\n",
      "55 0.010625198367429872\n",
      "56 0.010673933615206617\n",
      "57 0.010713578576788603\n",
      "58 0.01066485170632071\n",
      "59 0.01065733789206301\n",
      "60 0.010685483286673203\n",
      "61 0.010622999306212707\n",
      "62 0.010598181430635937\n",
      "63 0.010499351193708628\n",
      "64 0.010514781267306112\n",
      "65 0.010501771255672195\n",
      "66 0.010517854149415116\n",
      "67 0.010517319966127014\n",
      "68 0.01041922201461304\n",
      "69 0.01042678650070885\n",
      "70 0.010447975899792825\n",
      "71 0.01053725133619733\n",
      "72 0.010563120038240848\n",
      "73 0.010693332581729807\n",
      "74 0.010485263690985262\n",
      "75 0.0104996236237203\n",
      "76 0.010427993020391815\n",
      "77 0.010541999812817376\n",
      "78 0.010664933827954616\n",
      "79 0.010390827001389753\n",
      "80 0.010453036398694666\n",
      "81 0.010391404876996205\n",
      "82 0.010482925539902422\n",
      "83 0.010320937119407568\n",
      "84 0.010489104813067671\n",
      "85 0.010337715077420508\n",
      "86 0.01038921118999687\n",
      "87 0.010455970581598239\n",
      "88 0.010517707203796026\n",
      "89 0.010439947084613254\n",
      "90 0.010309239847138782\n",
      "91 0.0104701983178316\n",
      "92 0.010344864610445627\n",
      "93 0.010438373733527318\n",
      "94 0.01048688929679349\n",
      "95 0.010309860846784242\n",
      "96 0.010349864632936646\n",
      "97 0.010324200984990595\n",
      "98 0.010338061055520719\n",
      "99 0.010317411066527955\n",
      "100 0.010284719815186406\n",
      "101 0.010278975239279214\n",
      "102 0.0103469184217074\n",
      "103 0.010326785817268936\n",
      "104 0.010423134827150078\n",
      "105 0.010501882122168538\n",
      "106 0.010394117516678247\n",
      "107 0.010268033953988152\n",
      "108 0.01033275776545519\n",
      "109 0.010329244902567244\n",
      "110 0.01027876547359849\n",
      "111 0.010217595440723391\n",
      "112 0.01026932289909931\n",
      "113 0.010266588234299323\n",
      "114 0.010222656575354015\n",
      "115 0.01043192862737566\n",
      "116 0.010224838775125322\n",
      "117 0.010202163821975231\n",
      "118 0.010200118824539915\n",
      "119 0.010266753031756962\n",
      "120 0.010211820428600304\n",
      "121 0.010338556359271384\n",
      "122 0.010276029626415155\n",
      "123 0.010168392064180574\n",
      "124 0.010236625891508346\n",
      "125 0.010369236034480237\n",
      "126 0.01022827833394483\n",
      "127 0.010243228183708262\n",
      "128 0.010227013222419354\n",
      "129 0.010156622666975115\n",
      "130 0.010181174537714822\n",
      "131 0.010153900661623003\n",
      "132 0.010241788335153414\n",
      "133 0.01026154208405289\n",
      "134 0.010355887247390805\n",
      "135 0.01017079374739352\n",
      "136 0.010234051097561219\n",
      "137 0.010210562467342643\n",
      "138 0.010145417458545953\n",
      "139 0.010140959533486003\n",
      "140 0.010153941189276606\n",
      "141 0.010181584082046927\n",
      "142 0.010207872578638155\n",
      "143 0.010100849900306356\n",
      "144 0.010111802515181827\n",
      "145 0.010085686430826718\n",
      "146 0.010153484318361834\n",
      "147 0.010074253728091075\n",
      "148 0.010115097388791669\n",
      "149 0.010122012099976955\n",
      "150 0.010076409416066214\n",
      "151 0.010123141489152577\n",
      "152 0.010125445936199216\n",
      "153 0.010142850063378877\n",
      "154 0.010099148241054257\n",
      "155 0.010130290224715779\n",
      "156 0.010070032658315258\n",
      "157 0.010106950721050929\n",
      "158 0.010131852440678839\n",
      "159 0.010083509927543928\n",
      "160 0.010046233277442076\n",
      "161 0.010151118737031705\n",
      "162 0.01010508558537776\n",
      "163 0.010046566253656132\n",
      "164 0.010008427408327055\n",
      "165 0.010038241175046791\n",
      "166 0.01010128574769964\n",
      "167 0.010084781200066539\n",
      "168 0.010069870846119084\n",
      "169 0.01010550605790646\n",
      "170 0.010052179221496323\n",
      "171 0.010059536211386845\n",
      "172 0.009994891401584462\n",
      "173 0.010096432360126615\n",
      "174 0.010044161406291417\n",
      "175 0.010034857567049181\n",
      "176 0.010058706962641944\n",
      "177 0.010020991449578773\n",
      "178 0.01016144417868334\n",
      "179 0.009983286351092588\n",
      "180 0.01005338391881823\n",
      "181 0.010023099663842652\n",
      "182 0.010019812323122853\n",
      "183 0.009951309628155202\n",
      "184 0.010000392388573797\n",
      "185 0.009993978316934757\n",
      "186 0.01000636756428196\n",
      "187 0.009990448567847216\n",
      "188 0.010012544207501604\n",
      "189 0.010036319537106635\n",
      "190 0.010032423716530516\n",
      "191 0.010109998692796902\n",
      "192 0.010047232065636628\n",
      "193 0.009952655296072959\n",
      "194 0.009938337096593763\n",
      "195 0.009989390518461906\n",
      "196 0.009968684408146475\n",
      "197 0.010029499155963758\n",
      "198 0.009967119987437205\n",
      "199 0.009966832330173906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (extractor1): Linear(in_features=30, out_features=15, bias=True)\n",
       "  (extractor2): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (drop_out): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(n_epoch,model,loss_func,opt,train_dl,valid_dl)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: [[56844    17]\n",
      " [   19    82]]\n",
      "AUPRC score: 0.6728008024284751\n",
      "AUROC score: 0.9057911067130702\n",
      "Accuracy score: 0.9993679997191109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56861\n",
      "           1       0.83      0.81      0.82       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "ypred = model(torch.tensor(xtest).float()).detach().numpy()\n",
    "\n",
    "ypred [ypred>=0.5] =1.0\n",
    "ypred [ypred<0.5] =0.0\n",
    "print('Confusion matrix: {}'. format(metrics.confusion_matrix(ytest, ypred)))\n",
    "print('AUPRC score: {}'. format(metrics.average_precision_score(ytest, ypred)))\n",
    "print('AUROC score: {}'.format(metrics.roc_auc_score(ytest, ypred)))\n",
    "print('Accuracy score: {}'.format(metrics.accuracy_score(ytest, ypred)))\n",
    "print(metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17b4c01959b763961e65029bfd8cfa288ed8d0492d779c607a82e02daf2d74ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
