{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sys import float_info # Threshold smallest positive floating value\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Function - Returns N x 3 and labels\n",
    "def generate_data_from_gmm(N, pdf_params):\n",
    "    # Determine dimensionality from mixture PDF parameters\n",
    "    n = pdf_params['m'].shape[1]\n",
    "    # Output samples and labels\n",
    "    X = np.zeros([N, n])\n",
    "    labels = np.zeros(N)\n",
    "    \n",
    "    # Decide randomly which samples will come from each component\n",
    "    u = np.random.rand(N)\n",
    "    thresholds = np.cumsum(pdf_params['priors'])\n",
    "    thresholds = np.insert(thresholds, 0, 0) # For intervals of classes\n",
    "\n",
    "    L = np.array(range(1, len(pdf_params['priors'])+1))\n",
    "    for l in L:\n",
    "        # Get randomly sampled indices for this component\n",
    "        indices = np.argwhere((thresholds[l-1] <= u) & (u <= thresholds[l]))[:, 0]\n",
    "        # No. of samples in this component\n",
    "        Nl = len(indices)  \n",
    "        labels[indices] = l * np.ones(Nl) - 1\n",
    "        if n == 1:\n",
    "            X[indices, 0] =  norm.rvs(pdf_params['m'][l-1], pdf_params['C'][l-1], Nl)\n",
    "        else:\n",
    "            X[indices, :] =  multivariate_normal.rvs(pdf_params['m'][l-1], pdf_params['C'][l-1], Nl)\n",
    "    \n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Gaussian Data Params\n",
    "# Generate Data\n",
    "N = 500\n",
    "n = 3 # dimensionality of input random vectors\n",
    "C = 4 # number of classes\n",
    "gmm_pdf = {}\n",
    "gmm_pdf['priors'] = np.array([1/C, 1/C, 1/C, 1/C])\n",
    "gmm_pdf['m'] = np.array([1*np.ones(n), 4*np.ones(n), 6*np.ones(n), 9*np.ones(n)])\n",
    "gmm_pdf['C'] = np.array([2*np.eye(n), 2*np.eye(n), 2*np.eye(n), 2*np.eye(n)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwoLayerMLP class\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "class TwoLayerMLP(nn.Module):\n",
    "    # The nn.CrossEntropyLoss() loss function automatically performs a log_softmax() to \n",
    "    # the output when validating, on top of calculating the negative-log-likelihood using \n",
    "    # nn.NLLLoss(), while also being more stable numerically... So don't implement from scratch\n",
    "    \n",
    "    def __init__(self, d_in, d_hidden, C):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_in, d_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(d_hidden, C)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # fc to perceptrons\n",
    "        x = self.relu(x) # or self.softplus(x) for smooth-ReLU, empirically worse than ReLU\n",
    "        x = self.fc2(x)  # connect to output layer\n",
    "        x = self.log_softmax(x)  # for outputs that sum to 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train_model(model, data, labels, criterion, optimizer, num_epochs=25):\n",
    "    # Set up training data\n",
    "    X_train = torch.FloatTensor(data)\n",
    "    y_train = torch.LongTensor(labels)\n",
    "\n",
    "    # Optimize the neural network\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set grads to zero explicitly before backprop\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        # Criterion computes the cross entropy loss between input and target\n",
    "        loss = criterion(outputs, y_train)\n",
    "        # Backward pass to compute the gradients through the network\n",
    "        loss.backward()\n",
    "        # GD step update\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, data):\n",
    "    # Set up test data as tensor\n",
    "    X_test = torch.FloatTensor(data)\n",
    "\n",
    "    # Evaluate nn on test data and compare to true labels\n",
    "    predicted_labels = model(X_test)\n",
    "    # Back to numpy\n",
    "    predicted_labels = predicted_labels.detach().numpy()\n",
    "    \n",
    "    return np.argmax(predicted_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE Solution\n",
    "# Analytical optimal solution, aka the normal equation for least squares\n",
    "# Fit order d polynomial usins training data set with MLE method which\n",
    "# reduces to least-squares curve fitting here due to additive Gaussian noise\n",
    "def mle_solution(X, y):\n",
    "    # Model: y = phi(X)^T*theta\n",
    "    # LS estimate: theta^* = (phi(X)^T*phi(X))^-1 * phi(X)^T * y \n",
    "    return np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_preds, y_true):\n",
    "    # Residual error (X * theta) - y\n",
    "    error = y_preds - y_true\n",
    "    # Loss function is MSE\n",
    "    return np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_order_selection(X_train, y_train, folds, poly_deg):\n",
    "\n",
    "  C = len(np.unique(y_train))\n",
    "\n",
    "  cv = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "  # Polynomial degrees (\"hyperparameters\") to evaluate \n",
    "  degs = np.arange(1, poly_deg, 1)\n",
    "  n_degs = np.max(degs)\n",
    "\n",
    "  # scores = cross_val_score(estimator=trained_model, X=X_train, y=y_train, cv=cv, scoring='accuracy')\n",
    "  mse_valid_mk = np.empty((n_degs, folds)) \n",
    "  mse_train_mk = np.empty((n_degs, folds)) # Indexed by model m, data partition k\n",
    "  truelist=np.empty((n_degs,folds))\n",
    "  all_models = []\n",
    "\n",
    "  # \n",
    "  for deg in degs:\n",
    "    k = 0\n",
    "\n",
    "    # split training set for 10-fold cross validation\n",
    "    # for each of the 10 smaller sets, train model for 1-10 perceptrons\n",
    "    for fold, (train_indices, valid_indices) in enumerate(cv.split(X_train)):\n",
    "      # Extract the training and validation sets from the K-fold split\n",
    "      X_train_k = X_train[train_indices]\n",
    "      y_train_k = y_train[train_indices]\n",
    "      X_valid_k = X_train[valid_indices]\n",
    "      y_valid_k = y_train[valid_indices]\n",
    "\n",
    "      model = TwoLayerMLP(X_train.shape[1], deg, C)      \n",
    "      \n",
    "      optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      trained_model = train_model(model, X_train_k, y_train_k, criterion, optimizer, num_epochs=100)\n",
    "      all_models.append(trained_model)\n",
    "\n",
    "      y_train_pred = model_predict(trained_model,X_train_k)\n",
    "      y_valid_pred = model_predict(trained_model,X_valid_k)\n",
    "\n",
    "      truehit = len(np.argwhere(y_valid_pred == y_valid_k))\n",
    "      truelist[deg-1,k] = truehit/len(y_valid_k)\n",
    "\n",
    "      # Record MSE as well for this model and k-fold\n",
    "      mse_train_mk[deg - 1, k] = mse(y_train_pred, y_train_k)\n",
    "      mse_valid_mk[deg - 1, k] = mse(y_valid_pred, y_valid_k)\n",
    "      k += 1\n",
    "\n",
    "      # # Saving the model\n",
    "      # save_path = f'./model-fold-{fold}.pth'\n",
    "      # torch.save(model.state_dict(), save_path)\n",
    "    # print(\"hit rate: \", truelist)\n",
    "    #print(\"Num Perceptrons = \",deg, \" Hit Rate: \", np.mean(truelist[]))\n",
    "\n",
    "  hit_rate_train = np.mean(truelist, axis=1)\n",
    "\n",
    "  # STEP 3: Compute the average MSE loss for that model (based in this case on degree d)\n",
    "  mse_train_m = np.mean(mse_train_mk, axis=1) # Model average CV loss over folds\n",
    "  mse_valid_m = np.mean(mse_valid_mk, axis=1) \n",
    "\n",
    "\n",
    "  # +1 as the index starts from 0 while the degrees start from 1\n",
    "  optimal_d = np.argmin(mse_valid_m) + 1\n",
    "\n",
    "  optimal_model = all_models[optimal_d-1]\n",
    "  #print(\"The model selected to best fit the data without overfitting is: d={}\".format(optimal_d))\n",
    "  optimal_hit = hit_rate_train[optimal_d-1]\n",
    "  print(\"Perceptrons: \", optimal_d, \"  Hit Rate: \",optimal_hit)\n",
    "\n",
    "  return optimal_d, mse_valid_m, hit_rate_train, optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = generate_data_from_gmm(100000,gmm_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptrons:  7   Hit Rate:  0.7\n",
      "3.48759  = MSE\n",
      "Perceptrons:  8   Hit Rate:  0.645\n",
      "1.56735  = MSE\n",
      "Perceptrons:  9   Hit Rate:  0.6419999999999999\n",
      "1.50323  = MSE\n",
      "Perceptrons:  10   Hit Rate:  0.699\n",
      "1.45394  = MSE\n",
      "Perceptrons:  9   Hit Rate:  0.7170000000000001\n",
      "1.60141  = MSE\n",
      "Perceptrons:  10   Hit Rate:  0.7044\n",
      "1.79611  = MSE\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_all, ax_all = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "marker_shapes = 'ox+*.' # Accomodates up to C=5\n",
    "marker_colors = 'brgmy'\n",
    "degs = np.arange(1, 40, 4)\n",
    "\n",
    "N = [100, 200, 500, 1000, 2000, 5000]\n",
    "for samples in N:\n",
    "    X_train, y_train = generate_data_from_gmm(samples, gmm_pdf)\n",
    "    op_d, mse_val_m, hit_rate, opt_model = model_order_selection(X_train, y_train, 10, 11)\n",
    "    ax_all.scatter(degs,mse_val_m,label=samples)\n",
    "\n",
    "\n",
    "\n",
    "    # model = TwoLayerMLP(X_train.shape[1], op_d, C)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "    y_test_pred = model_predict(opt_model,X_test)\n",
    "    mse_test = mse(y_test_pred, y_test)\n",
    "    print(mse_test, \" = MSE\")\n",
    "\n",
    "    # truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "    # print(truehit/len(y_train))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"Num Perceptrons\")\n",
    "plt.ylabel(\"Hit Rate\")\n",
    "plt.show()\n",
    "N = 10000\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(opt_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\meuli\\Desktop\\ML\\EECE5644\\HW3\\hw3.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000027?line=0'>1</a>\u001b[0m op_d, mse_val_m \u001b[39m=\u001b[39m model_order_selection(X_train, y_train, \u001b[39m10\u001b[39;49m, \u001b[39m21\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000027?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m TwoLayerMLP(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], op_d, C)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000027?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\meuli\\Desktop\\ML\\EECE5644\\HW3\\hw3.ipynb Cell 12'\u001b[0m in \u001b[0;36mmodel_order_selection\u001b[1;34m(X_train, y_train, folds, poly_deg)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000025?line=30'>31</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000025?line=31'>32</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000025?line=32'>33</a>\u001b[0m trained_model \u001b[39m=\u001b[39m train_model(model, X_train_k, y_train_k, criterion, optimizer, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000025?line=34'>35</a>\u001b[0m y_train_pred \u001b[39m=\u001b[39m model_predict(trained_model,X_train_k)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000025?line=35'>36</a>\u001b[0m y_valid_pred \u001b[39m=\u001b[39m model_predict(trained_model,X_valid_k)\n",
      "\u001b[1;32mc:\\Users\\meuli\\Desktop\\ML\\EECE5644\\HW3\\hw3.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, data, labels, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000006?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000006?line=8'>9</a>\u001b[0m     \u001b[39m# Set grads to zero explicitly before backprop\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000006?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000006?line=10'>11</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(X_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000006?line=11'>12</a>\u001b[0m     \u001b[39m# Criterion computes the cross entropy loss between input and target\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000006?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, y_train)\n",
      "File \u001b[1;32mc:\\Users\\meuli\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\meuli\\Desktop\\ML\\EECE5644\\HW3\\hw3.ipynb Cell 5'\u001b[0m in \u001b[0;36mTwoLayerMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000005?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000005?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)  \u001b[39m# fc to perceptrons\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000005?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x) \u001b[39m# or self.softplus(x) for smooth-ReLU, empirically worse than ReLU\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000005?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)  \u001b[39m# connect to output layer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\meuli\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\meuli\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/meuli/anaconda3/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "op_d, mse_val_m = model_order_selection(X_train, y_train, 10, 21)\n",
    "\n",
    "model = TwoLayerMLP(X_train.shape[1], op_d, C)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "\n",
    "y_train_pred = model_predict(trained_model,X_train)\n",
    "\n",
    "truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "print(truehit/len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the Model?\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "K=10\n",
    "cv = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Polynomial degrees (\"hyperparameters\") to evaluate \n",
    "degs = np.arange(1, 21, 1)\n",
    "n_degs = np.max(degs)\n",
    "\n",
    "# scores = cross_val_score(estimator=trained_model, X=X_train, y=y_train, cv=cv, scoring='accuracy')\n",
    "mse_valid_mk = np.empty((n_degs, K)) \n",
    "mse_train_mk = np.empty((n_degs, K)) # Indexed by model m, data partition k\n",
    "truelist=np.empty((n_degs,K))\n",
    "for deg in degs:\n",
    "  k = 0\n",
    "  \n",
    "  # K-fold Cross Validation model evaluation\n",
    "  # truelist=[]\n",
    "\n",
    "  \n",
    "  for fold, (train_indices, valid_indices) in enumerate(cv.split(X_train)):\n",
    "    # Extract the training and validation sets from the K-fold split\n",
    "    X_train_k = X_train[train_indices]\n",
    "    y_train_k = y_train[train_indices]\n",
    "    X_valid_k = X_train[valid_indices]\n",
    "    y_valid_k = y_train[valid_indices]\n",
    "\n",
    "    model = TwoLayerMLP(X_train.shape[1], deg, C)\n",
    "    model.apply(reset_weights)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trained_model = train_model(model, X_train_k, y_train_k, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "    y_train_pred = model_predict(trained_model,X_train_k)\n",
    "    y_valid_pred = model_predict(trained_model,X_valid_k)\n",
    "\n",
    "    truehit = len(np.argwhere(y_valid_pred == y_valid_k))\n",
    "    truelist[deg -1, k] = truehit/len(y_valid_k)\n",
    "\n",
    "    # Record MSE as well for this model and k-fold\n",
    "    mse_train_mk[deg - 1, k] = mse(y_train_pred, y_train_k)\n",
    "    mse_valid_mk[deg - 1, k] = mse(y_valid_pred, y_valid_k)\n",
    "    k += 1\n",
    "\n",
    "    # # Saving the model\n",
    "    # save_path = f'./model-fold-{fold}.pth'\n",
    "    # torch.save(model.state_dict(), save_path)\n",
    "  # print(\"hit rate: \", truelist)\n",
    "  print(\"Num Perceptrons = \",deg, \" Hit Rate: \", np.mean(truelist[deg-1,:]))\n",
    "\n",
    "hit_rate_train = np.mean(truelist, axis=1)\n",
    "\n",
    "# STEP 3: Compute the average MSE loss for that model (based in this case on degree d)\n",
    "mse_train_m = np.mean(mse_train_mk, axis=1) # Model average CV loss over folds\n",
    "mse_valid_m = np.mean(mse_valid_mk, axis=1) \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mse_val_m)\n",
    "plt.show()\n",
    "\n",
    "# +1 as the index starts from 0 while the degrees start from 1\n",
    "optimal_d = np.argmin(mse_valid_m) + 1\n",
    "print(\"The model selected to best fit the data without overfitting is: d={}\".format(optimal_d))\n",
    "optimal_hit = hit_rate_train[optimal_d-1]\n",
    "print(\"optimal hit at \", optimal_hit)\n",
    "\n",
    "model = TwoLayerMLP(X_train.shape[1], optimal_d, C)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "y_train_pred = model_predict(trained_model,X_train)\n",
    "\n",
    "truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "print(truehit/len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(degs,hit_rate_train*100)\n",
    "plt.xlabel(\"Num Perceptrons\")\n",
    "plt.ylabel(\"Hit Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_train = np.mean(truelist, axis=1)\n",
    "print(hit_rate_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "model = TwoLayerMLP(X_train.shape[1], optimal_d, C)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "y_train_pred = model_predict(trained_model,X_train)\n",
    "\n",
    "truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "print(truehit/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE vs degree\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.plot(degs, mse_train_m, color=\"b\", marker=\"s\", label=r\"$D_{train}$\")\n",
    "ax.plot(degs, mse_valid_m, color=\"r\", marker=\"x\", label=r\"$D_{valid}$\")\n",
    "\n",
    "# Use logarithmic y-scale as MSE values get very large\n",
    "ax.set_yscale('log')\n",
    "# Force x-axis for degrees to be integer\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.legend(loc='upper left', shadow=True)\n",
    "plt.xlabel(\"Model Polynomial Order\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE estimates with {}-fold cross-validation\".format(K))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "num_folds = 10\n",
    "\n",
    "cv = KFold(n_splits=num_folds, random_state=1, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold in np.arange(1, num_folds+1):\n",
    "\n",
    "    # Set up training data\n",
    "    X_train = torch.FloatTensor(X)\n",
    "    y_train = torch.LongTensor(labels)\n",
    "\n",
    "    model = TwoLayerMLP(X.shape[1], 16, C)\n",
    "    model.apply(reset_weights)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Optimize the neural network\n",
    "    for epoch in range(num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set grads to zero explicitly before backprop\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        # Criterion computes the cross entropy loss between input and target\n",
    "        loss = criterion(outputs, y_train)\n",
    "        # Backward pass to compute the gradients through the network\n",
    "        loss.backward()\n",
    "        # GD step update\n",
    "        optimizer.step()\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "\n",
    "scores = cross_val_score(model, X, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "\n",
    "model = train_model(model, X, labels, criterion, optimizer, num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17b4c01959b763961e65029bfd8cfa288ed8d0492d779c607a82e02daf2d74ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
