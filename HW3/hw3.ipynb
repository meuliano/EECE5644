{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sys import float_info # Threshold smallest positive floating value\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Function - Returns N x 3 and labels\n",
    "def generate_data_from_gmm(N, pdf_params):\n",
    "    # Determine dimensionality from mixture PDF parameters\n",
    "    n = pdf_params['m'].shape[1]\n",
    "    # Output samples and labels\n",
    "    X = np.zeros([N, n])\n",
    "    labels = np.zeros(N)\n",
    "    \n",
    "    # Decide randomly which samples will come from each component\n",
    "    u = np.random.rand(N)\n",
    "    thresholds = np.cumsum(pdf_params['priors'])\n",
    "    thresholds = np.insert(thresholds, 0, 0) # For intervals of classes\n",
    "\n",
    "    L = np.array(range(1, len(pdf_params['priors'])+1))\n",
    "    for l in L:\n",
    "        # Get randomly sampled indices for this component\n",
    "        indices = np.argwhere((thresholds[l-1] <= u) & (u <= thresholds[l]))[:, 0]\n",
    "        # No. of samples in this component\n",
    "        Nl = len(indices)  \n",
    "        labels[indices] = l * np.ones(Nl) - 1\n",
    "        if n == 1:\n",
    "            X[indices, 0] =  norm.rvs(pdf_params['m'][l-1], pdf_params['C'][l-1], Nl)\n",
    "        else:\n",
    "            X[indices, :] =  multivariate_normal.rvs(pdf_params['m'][l-1], pdf_params['C'][l-1], Nl)\n",
    "    \n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERM classification rule (min prob. of error classifier)\n",
    "def perform_erm_classification(X, Lambda, gmm_params, C):    \n",
    "    # Conditional likelihoods of each x given each class, shape (C, N)\n",
    "    class_cond_likelihoods = np.array([multivariate_normal.pdf(X, gmm_params['m'][c], gmm_params['C'][c]) for c in range(C)])\n",
    "\n",
    "    # Take diag so we have (C, C) shape of priors with prior prob along diagonal\n",
    "    class_priors = np.diag(gmm_params['priors'])\n",
    "    # class_priors*likelihood with diagonal matrix creates a matrix of posterior probabilities\n",
    "    # with each class as a row and N columns for samples, e.g. row 1: [p(y1)p(x1|y1), ..., p(y1)p(xN|y1)]\n",
    "    class_posteriors = class_priors.dot(class_cond_likelihoods)\n",
    "\n",
    "    # Conditional risk matrix of size C x N with each class as a row and N columns for samples\n",
    "    risk_mat = Lambda.dot(class_posteriors)\n",
    "    \n",
    "    return np.argmin(risk_mat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Gaussian Data Params\n",
    "# Generate Data\n",
    "N = 500\n",
    "n = 3 # dimensionality of input random vectors\n",
    "C = 4 # number of classes\n",
    "gmm_pdf = {}\n",
    "gmm_pdf['priors'] = np.array([1/C, 1/C, 1/C, 1/C])\n",
    "mu0 = [2,  2,  2]\n",
    "mu1 = [2, -2,  2]\n",
    "mu2 = [2, -2, -2]\n",
    "mu3 = [2,  2, -2]\n",
    "gmm_pdf['m'] = np.array([mu0, mu1, mu2, mu3])\n",
    "gmm_pdf['C'] = np.array([2*np.eye(n), 2*np.eye(n), 2*np.eye(n), 2*np.eye(n)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (rows: Predicted class, columns: True class):\n",
      "[[114  14   0   8]\n",
      " [  8 107   9   0]\n",
      " [  0  11 106   6]\n",
      " [  9   0   6 102]]\n",
      "Total Mumber of Misclassified Samples: 71\n",
      "Empirically Estimated Probability of Error: 0.1420\n"
     ]
    }
   ],
   "source": [
    "X, labels = generate_data_from_gmm(N, gmm_pdf)\n",
    "\n",
    "# If 0-1 loss then yield MAP decision rule, else ERM classifier\n",
    "Lambda = np.ones((C, C)) - np.eye(C)\n",
    "\n",
    "# ERM decision rule, take index/label associated with minimum conditional risk as decision (N, 1)\n",
    "decisions = perform_erm_classification(X, Lambda, gmm_pdf, C)\n",
    "\n",
    "# Simply using sklearn confusion matrix\n",
    "print(\"Confusion Matrix (rows: Predicted class, columns: True class):\")\n",
    "conf_mat = confusion_matrix(decisions, labels)\n",
    "print(conf_mat)\n",
    "\n",
    "correct_class_samples = np.sum(np.diag(conf_mat))\n",
    "print(\"Total Mumber of Misclassified Samples: {:d}\".format(N - correct_class_samples))\n",
    "\n",
    "prob_error = 1 - (correct_class_samples / N)\n",
    "print(\"Empirically Estimated Probability of Error: {:.4f}\".format(prob_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwoLayerMLP class\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "class TwoLayerMLP(nn.Module):\n",
    "    # The nn.CrossEntropyLoss() loss function automatically performs a log_softmax() to \n",
    "    # the output when validating, on top of calculating the negative-log-likelihood using \n",
    "    # nn.NLLLoss(), while also being more stable numerically... So don't implement from scratch\n",
    "    \n",
    "    def __init__(self, d_in, d_hidden, C):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_in, d_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(d_hidden, C)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # fc to perceptrons\n",
    "        x = self.relu(x) # or self.softplus(x) for smooth-ReLU, empirically worse than ReLU\n",
    "        x = self.fc2(x)  # connect to output layer\n",
    "        x = self.log_softmax(x)  # for outputs that sum to 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train_model(model, data, labels, criterion, optimizer, num_epochs=25):\n",
    "    # Set up training data\n",
    "    X_train = torch.FloatTensor(data)\n",
    "    y_train = torch.LongTensor(labels)\n",
    "\n",
    "    # Optimize the neural network\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set grads to zero explicitly before backprop\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        # Criterion computes the cross entropy loss between input and target\n",
    "        loss = criterion(outputs, y_train)\n",
    "        # Backward pass to compute the gradients through the network\n",
    "        loss.backward()\n",
    "        # GD step update\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, data):\n",
    "    # Set up test data as tensor\n",
    "    X_test = torch.FloatTensor(data)\n",
    "\n",
    "    # Evaluate nn on test data and compare to true labels\n",
    "    predicted_labels = model(X_test)\n",
    "    # Back to numpy\n",
    "    predicted_labels = predicted_labels.detach().numpy()\n",
    "    \n",
    "    return np.argmax(predicted_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE Solution\n",
    "# Analytical optimal solution, aka the normal equation for least squares\n",
    "# Fit order d polynomial usins training data set with MLE method which\n",
    "# reduces to least-squares curve fitting here due to additive Gaussian noise\n",
    "def mle_solution(X, y):\n",
    "    # Model: y = phi(X)^T*theta\n",
    "    # LS estimate: theta^* = (phi(X)^T*phi(X))^-1 * phi(X)^T * y \n",
    "    return np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_preds, y_true):\n",
    "    # Residual error (X * theta) - y\n",
    "    error = y_preds - y_true\n",
    "    # Loss function is MSE\n",
    "    return np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_order_selection(X_train, y_train, folds, poly_deg):\n",
    "\n",
    "  C = len(np.unique(y_train))\n",
    "\n",
    "  cv = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "  # Polynomial degrees (\"hyperparameters\") to evaluate \n",
    "  degs = np.arange(1, poly_deg, 1)\n",
    "  n_degs = np.max(degs)\n",
    "\n",
    "  # scores = cross_val_score(estimator=trained_model, X=X_train, y=y_train, cv=cv, scoring='accuracy')\n",
    "  mse_valid_mk = np.empty((n_degs, folds)) \n",
    "  mse_train_mk = np.empty((n_degs, folds)) # Indexed by model m, data partition k\n",
    "  truelist=np.empty((n_degs,folds))\n",
    "  all_models = []\n",
    "\n",
    "  # \n",
    "  for deg in degs:\n",
    "    k = 0\n",
    "\n",
    "    # split training set for 10-fold cross validation\n",
    "    # for each of the 10 smaller sets, train model for 1-10 perceptrons\n",
    "    for fold, (train_indices, valid_indices) in enumerate(cv.split(X_train)):\n",
    "      # Extract the training and validation sets from the K-fold split\n",
    "      X_train_k = X_train[train_indices]\n",
    "      y_train_k = y_train[train_indices]\n",
    "      X_valid_k = X_train[valid_indices]\n",
    "      y_valid_k = y_train[valid_indices]\n",
    "\n",
    "      model = TwoLayerMLP(X_train.shape[1], deg, C)      \n",
    "      \n",
    "      optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      trained_model = train_model(model, X_train_k, y_train_k, criterion, optimizer, num_epochs=100)\n",
    "      all_models.append(trained_model)\n",
    "\n",
    "      y_train_pred = model_predict(trained_model,X_train_k)\n",
    "      y_valid_pred = model_predict(trained_model,X_valid_k)\n",
    "\n",
    "      truehit = len(np.argwhere(y_valid_pred == y_valid_k))\n",
    "      truelist[deg-1,k] = truehit/len(y_valid_k)\n",
    "\n",
    "      # Record MSE as well for this model and k-fold\n",
    "      mse_train_mk[deg - 1, k] = mse(y_train_pred, y_train_k)\n",
    "      mse_valid_mk[deg - 1, k] = mse(y_valid_pred, y_valid_k)\n",
    "      k += 1\n",
    "\n",
    "      # # Saving the model\n",
    "      # save_path = f'./model-fold-{fold}.pth'\n",
    "      # torch.save(model.state_dict(), save_path)\n",
    "    # print(\"hit rate: \", truelist)\n",
    "    #print(\"Num Perceptrons = \",deg, \" Hit Rate: \", np.mean(truelist[]))\n",
    "\n",
    "  hit_rate_train = np.mean(truelist, axis=1)\n",
    "\n",
    "  # STEP 3: Compute the average MSE loss for that model (based in this case on degree d)\n",
    "  mse_train_m = np.mean(mse_train_mk, axis=1) # Model average CV loss over folds\n",
    "  mse_valid_m = np.mean(mse_valid_mk, axis=1) \n",
    "\n",
    "\n",
    "  # +1 as the index starts from 0 while the degrees start from 1\n",
    "  optimal_d = np.argmin(mse_valid_m) + 1\n",
    "\n",
    "  optimal_model = all_models[optimal_d-1]\n",
    "  #print(\"The model selected to best fit the data without overfitting is: d={}\".format(optimal_d))\n",
    "  optimal_hit = hit_rate_train[optimal_d-1]\n",
    "  print(\"Perceptrons: \", optimal_d, \"  Hit Rate: \",optimal_hit)\n",
    "\n",
    "  return optimal_d, mse_valid_m, hit_rate_train, optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = generate_data_from_gmm(100000,gmm_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptrons:  8   Hit Rate:  0.8099999999999999\n",
      "1.50068  = MSE\n",
      "Perceptrons:  14   Hit Rate:  0.875\n",
      "0.46456  = MSE\n",
      "Perceptrons:  20   Hit Rate:  0.858\n",
      "0.95924  = MSE\n",
      "Perceptrons:  16   Hit Rate:  0.8400000000000001\n",
      "0.80759  = MSE\n",
      "Perceptrons:  17   Hit Rate:  0.8515\n",
      "0.7325  = MSE\n",
      "Perceptrons:  12   Hit Rate:  0.8506\n",
      "1.42784  = MSE\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_all, ax_all = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "marker_shapes = 'ox+*.' # Accomodates up to C=5\n",
    "marker_colors = 'brgmy'\n",
    "degs = np.arange(1, 80, 4)\n",
    "\n",
    "N = [100, 200, 500, 1000, 2000, 5000]\n",
    "for samples in N:\n",
    "    X_train, y_train = generate_data_from_gmm(samples, gmm_pdf)\n",
    "    op_d, mse_val_m, hit_rate, opt_model = model_order_selection(X_train, y_train, folds=10, poly_deg=21)\n",
    "    ax_all.scatter(degs,mse_val_m,label=samples)\n",
    "\n",
    "\n",
    "\n",
    "    # model = TwoLayerMLP(X_train.shape[1], op_d, C)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "    y_test_pred = model_predict(opt_model,X_test)\n",
    "    mse_test = mse(y_test_pred, y_test)\n",
    "    print(mse_test, \" = MSE\")\n",
    "\n",
    "    # truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "    # print(truehit/len(y_train))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"Num Perceptrons\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "N = 10000\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_pre_hooks', '_get_backward_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'fc1', 'fc2', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'load_state_dict', 'log_softmax', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_module', 'register_parameter', 'relu', 'requires_grad_', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(opt_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptrons:  18   Hit Rate:  0.5780000000000001\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\meuli\\Desktop\\ML\\EECE5644\\HW3\\hw3.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000012?line=0'>1</a>\u001b[0m op_d, mse_val_m \u001b[39m=\u001b[39m model_order_selection(X_train, y_train, \u001b[39m10\u001b[39m, \u001b[39m21\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000012?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m TwoLayerMLP(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], op_d, C)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/meuli/Desktop/ML/EECE5644/HW3/hw3.ipynb#ch0000012?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "op_d, mse_val_m = model_order_selection(X_train, y_train, 10, 21)\n",
    "\n",
    "model = TwoLayerMLP(X_train.shape[1], op_d, C)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "\n",
    "y_train_pred = model_predict(trained_model,X_train)\n",
    "\n",
    "truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "print(truehit/len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the Model?\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "K=10\n",
    "cv = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Polynomial degrees (\"hyperparameters\") to evaluate \n",
    "degs = np.arange(1, 21, 1)\n",
    "n_degs = np.max(degs)\n",
    "\n",
    "# scores = cross_val_score(estimator=trained_model, X=X_train, y=y_train, cv=cv, scoring='accuracy')\n",
    "mse_valid_mk = np.empty((n_degs, K)) \n",
    "mse_train_mk = np.empty((n_degs, K)) # Indexed by model m, data partition k\n",
    "truelist=np.empty((n_degs,K))\n",
    "for deg in degs:\n",
    "  k = 0\n",
    "  \n",
    "  # K-fold Cross Validation model evaluation\n",
    "  # truelist=[]\n",
    "\n",
    "  \n",
    "  for fold, (train_indices, valid_indices) in enumerate(cv.split(X_train)):\n",
    "    # Extract the training and validation sets from the K-fold split\n",
    "    X_train_k = X_train[train_indices]\n",
    "    y_train_k = y_train[train_indices]\n",
    "    X_valid_k = X_train[valid_indices]\n",
    "    y_valid_k = y_train[valid_indices]\n",
    "\n",
    "    model = TwoLayerMLP(X_train.shape[1], deg, C)\n",
    "    model.apply(reset_weights)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trained_model = train_model(model, X_train_k, y_train_k, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "    y_train_pred = model_predict(trained_model,X_train_k)\n",
    "    y_valid_pred = model_predict(trained_model,X_valid_k)\n",
    "\n",
    "    truehit = len(np.argwhere(y_valid_pred == y_valid_k))\n",
    "    truelist[deg -1, k] = truehit/len(y_valid_k)\n",
    "\n",
    "    # Record MSE as well for this model and k-fold\n",
    "    mse_train_mk[deg - 1, k] = mse(y_train_pred, y_train_k)\n",
    "    mse_valid_mk[deg - 1, k] = mse(y_valid_pred, y_valid_k)\n",
    "    k += 1\n",
    "\n",
    "    # # Saving the model\n",
    "    # save_path = f'./model-fold-{fold}.pth'\n",
    "    # torch.save(model.state_dict(), save_path)\n",
    "  # print(\"hit rate: \", truelist)\n",
    "  print(\"Num Perceptrons = \",deg, \" Hit Rate: \", np.mean(truelist[deg-1,:]))\n",
    "\n",
    "hit_rate_train = np.mean(truelist, axis=1)\n",
    "\n",
    "# STEP 3: Compute the average MSE loss for that model (based in this case on degree d)\n",
    "mse_train_m = np.mean(mse_train_mk, axis=1) # Model average CV loss over folds\n",
    "mse_valid_m = np.mean(mse_valid_mk, axis=1) \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mse_val_m)\n",
    "plt.show()\n",
    "\n",
    "# +1 as the index starts from 0 while the degrees start from 1\n",
    "optimal_d = np.argmin(mse_valid_m) + 1\n",
    "print(\"The model selected to best fit the data without overfitting is: d={}\".format(optimal_d))\n",
    "optimal_hit = hit_rate_train[optimal_d-1]\n",
    "print(\"optimal hit at \", optimal_hit)\n",
    "\n",
    "model = TwoLayerMLP(X_train.shape[1], optimal_d, C)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "y_train_pred = model_predict(trained_model,X_train)\n",
    "\n",
    "truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "print(truehit/len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(degs,hit_rate_train*100)\n",
    "plt.xlabel(\"Num Perceptrons\")\n",
    "plt.ylabel(\"Hit Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_train = np.mean(truelist, axis=1)\n",
    "print(hit_rate_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "model = TwoLayerMLP(X_train.shape[1], optimal_d, C)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model = train_model(model, X_train, y_train, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "y_train_pred = model_predict(trained_model,X_train)\n",
    "\n",
    "truehit = len(np.argwhere(y_train_pred == y_train))\n",
    "print(truehit/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE vs degree\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.plot(degs, mse_train_m, color=\"b\", marker=\"s\", label=r\"$D_{train}$\")\n",
    "ax.plot(degs, mse_valid_m, color=\"r\", marker=\"x\", label=r\"$D_{valid}$\")\n",
    "\n",
    "# Use logarithmic y-scale as MSE values get very large\n",
    "ax.set_yscale('log')\n",
    "# Force x-axis for degrees to be integer\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.legend(loc='upper left', shadow=True)\n",
    "plt.xlabel(\"Model Polynomial Order\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE estimates with {}-fold cross-validation\".format(K))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "num_folds = 10\n",
    "\n",
    "cv = KFold(n_splits=num_folds, random_state=1, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold in np.arange(1, num_folds+1):\n",
    "\n",
    "    # Set up training data\n",
    "    X_train = torch.FloatTensor(X)\n",
    "    y_train = torch.LongTensor(labels)\n",
    "\n",
    "    model = TwoLayerMLP(X.shape[1], 16, C)\n",
    "    model.apply(reset_weights)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Optimize the neural network\n",
    "    for epoch in range(num_epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set grads to zero explicitly before backprop\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        # Criterion computes the cross entropy loss between input and target\n",
    "        loss = criterion(outputs, y_train)\n",
    "        # Backward pass to compute the gradients through the network\n",
    "        loss.backward()\n",
    "        # GD step update\n",
    "        optimizer.step()\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "\n",
    "scores = cross_val_score(model, X, labels, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "\n",
    "model = train_model(model, X, labels, criterion, optimizer, num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17b4c01959b763961e65029bfd8cfa288ed8d0492d779c607a82e02daf2d74ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
